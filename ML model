{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8406143,"sourceType":"datasetVersion","datasetId":3767049},{"sourceId":12799601,"sourceType":"datasetVersion","datasetId":8092693},{"sourceId":12799692,"sourceType":"datasetVersion","datasetId":8092758}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/marinab11/transaction-categorisation-model?scriptVersionId=256732115\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Transaction Categorization Model - Live Demo\n### Automatically classifies household transactions into categories using text descriptions\n\nThis model uses:\n- **TF-IDF** for text vectorization\n- **Logistic Regression** for classification\n- Custom category merging for rare transactions\n\n**Accuracy**: 91% (see full metrics below)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sentence_transformers import SentenceTransformer\n\n\n# Load dataset\n\ndf1 = pd.read_csv('/kaggle/input/daily-transactions-dataset/Daily Household Transactions.csv')\n\n# new balanced dataset\ndf2 = pd.read_csv('/kaggle/input/synthetic-balanced-expenses/synthetic_expenses (1).csv')\n\ndf3 = pd.read_csv('/kaggle/input/selected-expense-categories-to-reduce-bias/synthetic_expenses_selected_categories.csv')\n\n# combine them into one DataFrame (if you want to train on both)\ndf = pd.concat([df1, df2, df3], ignore_index=True)\n\n# Clean text column (example: 'Note')\ndef clean_text(text):\n    text = str(text).lower()\n    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # remove punctuation/numbers\n    return text.strip()\n\ndf['cleaned_note'] = df['Note'].apply(clean_text)\ndf['Category'] = df['Category'].str.lower().str.strip()\n\n# --------------------------\n# Merge rare categories into \"Rare\" and very rare into \"Other\"\nthreshold = 100  # Any category with count < 100 will be grouped as \"Other\"\n\ncategory_counts = df['Category'].value_counts()\n\n# Categories to be grouped as \"Other\"\nsmall_categories = category_counts[category_counts < threshold].index\n\n# Apply mapping\ndf['Category'] = df['Category'].apply(lambda cat: \"other\" if cat in small_categories else cat)\n\n# Print counts to verify\nprint(\"Final Category Counts:\")\nprint(df['Category'].value_counts())\n\nprint(\"\\nCategories grouped as 'Other':\")\nprint(list(small_categories))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T04:00:32.909039Z","iopub.execute_input":"2025-08-19T04:00:32.909293Z","iopub.status.idle":"2025-08-19T04:01:09.554645Z","shell.execute_reply.started":"2025-08-19T04:00:32.909267Z","shell.execute_reply":"2025-08-19T04:01:09.553863Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Simple text cleaning function\ndef clean_text(text):\n    text = str(text).lower()  # Lowercase & convert to string\n    text = ''.join(c for c in text if c.isalnum() or c.isspace())  # Remove punctuation\n    return text\n\n# Adjust column name here if your CSV shows something different\ndf['cleaned_note'] = df['Note'].astype(str).apply(clean_text)\n\n# Check a sample\ndf[['Note', 'cleaned_note']].head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T04:01:09.556727Z","iopub.execute_input":"2025-08-19T04:01:09.557007Z","iopub.status.idle":"2025-08-19T04:01:09.598541Z","shell.execute_reply.started":"2025-08-19T04:01:09.556985Z","shell.execute_reply":"2025-08-19T04:01:09.5976Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df['Category'].value_counts())\n\n# Optional: If there are too few samples for some categories, you may remove them\ndf = df[df['Category'].map(df['Category'].value_counts()) > 1]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T04:01:09.601803Z","iopub.execute_input":"2025-08-19T04:01:09.602101Z","iopub.status.idle":"2025-08-19T04:01:09.642113Z","shell.execute_reply.started":"2025-08-19T04:01:09.602072Z","shell.execute_reply":"2025-08-19T04:01:09.641187Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df['cleaned_note']\ny = df['Category']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T04:01:09.643022Z","iopub.execute_input":"2025-08-19T04:01:09.64331Z","iopub.status.idle":"2025-08-19T04:01:09.659086Z","shell.execute_reply.started":"2025-08-19T04:01:09.643282Z","shell.execute_reply":"2025-08-19T04:01:09.658222Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer()\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T04:01:09.659894Z","iopub.execute_input":"2025-08-19T04:01:09.66018Z","iopub.status.idle":"2025-08-19T04:01:09.727121Z","shell.execute_reply.started":"2025-08-19T04:01:09.660151Z","shell.execute_reply":"2025-08-19T04:01:09.726448Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"models = {\n    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n    \"Naive Bayes\": MultinomialNB(),\n    \"Linear SVM\": LinearSVC(),\n    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42)\n}\n\nresults = {}\n\nfor name, clf in models.items():\n    clf.fit(X_train_tfidf, y_train)\n    y_pred = clf.predict(X_test_tfidf)\n    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n    results[name] = {\n        \"Accuracy\": report[\"accuracy\"],\n        \"Macro F1\": report[\"macro avg\"][\"f1-score\"],\n        \"Weighted F1\": report[\"weighted avg\"][\"f1-score\"]\n    }\n\n# Convert results to a nice table\nresults_df = pd.DataFrame(results).T\nprint(results_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T04:01:09.729116Z","iopub.execute_input":"2025-08-19T04:01:09.7294Z","iopub.status.idle":"2025-08-19T04:01:11.547991Z","shell.execute_reply.started":"2025-08-19T04:01:09.72938Z","shell.execute_reply":"2025-08-19T04:01:11.547201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# Encode train/test data\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\nX_train_emb = model.encode(X_train.tolist(), show_progress_bar=True)\nX_test_emb = model.encode(X_test.tolist(), show_progress_bar=True)\n\n# Train Logistic Regression\nclf = LogisticRegression(max_iter=2000)\nclf.fit(X_train_emb, y_train)\n\n# Predictions\ny_pred = clf.predict(X_test_emb)\n\n# Print results\nacc = accuracy_score(y_test, y_pred)\nprint(\"Embedding-based Logistic Regression\")\nprint(\"Accuracy:\", acc)\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred, zero_division=0))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T04:01:11.548786Z","iopub.execute_input":"2025-08-19T04:01:11.549072Z","iopub.status.idle":"2025-08-19T04:01:31.415462Z","shell.execute_reply.started":"2025-08-19T04:01:11.549048Z","shell.execute_reply":"2025-08-19T04:01:31.41404Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(max_iter=1000)\nmodel.fit(X_train_tfidf, y_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T04:01:31.416243Z","iopub.execute_input":"2025-08-19T04:01:31.416544Z","iopub.status.idle":"2025-08-19T04:01:31.941739Z","shell.execute_reply.started":"2025-08-19T04:01:31.416519Z","shell.execute_reply":"2025-08-19T04:01:31.940988Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ny_pred = model.predict(X_test_tfidf)\n\n# Avoid division warnings by setting zero_division=0\nprint(classification_report(y_test, y_pred, zero_division=0))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T04:01:31.942319Z","iopub.execute_input":"2025-08-19T04:01:31.942587Z","iopub.status.idle":"2025-08-19T04:01:32.023077Z","shell.execute_reply.started":"2025-08-19T04:01:31.942565Z","shell.execute_reply":"2025-08-19T04:01:32.022099Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example new notes to classify\ntest_notes = [\n    \"Bought pizza from Pizza Hut\",\n    \"Monthly gym subscription payment\",\n    \"Bus ticket to office\",\n    \"Paid electricity bill\",\n    \"Investment in mutual fund\"\n]\n\n# Clean the test notes using the same function\ncleaned_test_notes = [clean_text(note) for note in test_notes]\n\n# Vectorize the cleaned test notes\ntest_tfidf = vectorizer.transform(cleaned_test_notes)\n\n# Predict categories\npredictions = model.predict(test_tfidf)\n\n# Print results\nfor note, category in zip(test_notes, predictions):\n    print(f\"Note: '{note}' --> Predicted Category: '{category}'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T04:01:32.023733Z","iopub.execute_input":"2025-08-19T04:01:32.024483Z","iopub.status.idle":"2025-08-19T04:01:32.032969Z","shell.execute_reply.started":"2025-08-19T04:01:32.024454Z","shell.execute_reply":"2025-08-19T04:01:32.032146Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 9 - Interactive demo with ipywidgets\n\nfrom ipywidgets import interact, Dropdown\n\n# Dictionary of demo examples\ndemo_examples = {\n    \"üçï Food\": \"Bought pizza from Pizza Hut\",\n    \"üí™ Fitness\": \"Monthly gym subscription payment\",\n    \"üöå Transport\": \"Bus ticket to office\",\n    \"üí° Bills\": \"Paid electricity bill\",\n    \"üìà Investment\": \"Investment in mutual fund\"\n}\n\ndef predict_transaction(note=\"\", example=\"\"):\n    # Use user input or selected example\n    input_text = note if note else demo_examples.get(example, \"\")\n    \n    if not input_text:\n        print(\"‚ö†Ô∏è Please enter text or select an example\")\n        return\n    \n    # Clean and predict\n    cleaned = clean_text(input_text)\n    X = vectorizer.transform([cleaned])\n    pred = model.predict(X)[0]\n    proba = model.predict_proba(X).max()\n    \n    print(f\"\\nüìù Note: '{input_text}'\")\n    print(f\"üè∑Ô∏è Predicted Category: '{pred}' (confidence: {proba:.1%})\")\n    print(\"\\nTop 3 Categories:\")\n    for i, (cat, score) in enumerate(\n        sorted(zip(model.classes_, model.predict_proba(X)[0]), key=lambda x: -x[1])[:3],\n        1\n    ):\n        print(f\"{i}. {cat}: {score:.1%}\")\n\n# Interactive widget\ninteract(\n    predict_transaction,\n    note=\"\",\n    example=Dropdown(options=[\"\"] + list(demo_examples.keys()), description=\"Example:\")\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T04:01:32.033806Z","iopub.execute_input":"2025-08-19T04:01:32.034933Z","iopub.status.idle":"2025-08-19T04:01:32.071273Z","shell.execute_reply.started":"2025-08-19T04:01:32.034906Z","shell.execute_reply":"2025-08-19T04:01:32.07042Z"}},"outputs":[],"execution_count":null}]}